{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d28665",
   "metadata": {},
   "source": [
    "Case 1 :\n",
    " A product-based company has experienced a continuous revenue decline over the past five\n",
    " months. The CEO wants a comprehensive diagnostic analysis to uncover the root causes.\n",
    " The focus should be on understanding key metrics, evaluating product performance, and\n",
    " assessing the contributions and efficiency of each team, including Sales, Marketing, Product\n",
    " Development,Branding and Customer Support.\n",
    " The CEO also wants insights into external factors, such as market trends and competitor\n",
    " dynamics, to determine their role in the revenue decline. The goal is to provide actionable\n",
    " recommendations to address the root causes and create a sustainable strategy for recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a90eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f730ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\Projects\\Guvi_DA_task\\sample_data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52955ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [c.strip().replace(\" \", \"_\").lower() for c in df.columns]\n",
    "df['sales_date'] = pd.to_datetime(df['sales_date'], errors='coerce')\n",
    "df['lead_registered_time'] = pd.to_datetime(df['lead_registered_time'], errors='coerce')\n",
    "df['product_amount_with_gst'] = pd.to_numeric(df['product_amount_with_gst'], errors='coerce').fillna(0)\n",
    "df['user_id'] = df['user_id'].astype(str)\n",
    "df['coupon_code'] = df['coupon_code'].fillna(\"NoCoupon\")\n",
    "df['payment_mode'] = df['payment_mode'].fillna(\"Unknown\")\n",
    "df['transaction_bank'] = df['transaction_bank'].fillna(\"Unknown\")\n",
    "df['payment_status'] = df['payment_status'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2062c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['sales_date'].isna()].copy()  \n",
    "df['sales_month'] = df['sales_date'].dt.to_period('M').dt.to_timestamp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbab2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"task2_questions_by_step\"\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49861874",
   "metadata": {},
   "source": [
    "Solving the case study questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea71b649",
   "metadata": {},
   "source": [
    "Q1. 1.Read and understand the case, then list all the Key Performance Indicators (KPIs) you will\n",
    " check for this data analysis (product-wise and team-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3daaf07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product KPIs (top 10 by revenue)\n",
      "product_code  total_revenue  transactions  avg_order_value  unique_customers  repeat_customer_rate_pct  payment_success_rate_pct  coupon_usage_rate_pct  median_lead_to_purchase_days\n",
      "    Product1      3695029.2          1272      2904.897170               725                 17.216981                       0.0              25.864780                          -1.0\n",
      "    Product4      2035095.0          1020      1995.191176               842                 11.764706                       0.0               0.000000                          -1.0\n",
      "    Product3      1617387.0           838      1930.056086               541                 19.093079                       0.0               0.477327                          -1.0\n",
      "    Product8      1411420.0          1560       904.756410              1029                 18.846154                       0.0               4.743590                          -1.0\n",
      "    Product5       944046.0           504      1873.107143               315                 20.634921                       0.0               3.769841                          -1.0\n",
      "    Product2       417582.0           418       999.000000               335                 12.440191                       0.0               0.000000                          -1.0\n",
      "   Product10       359640.0           360       999.000000               255                 16.388889                       0.0               0.000000                          -1.0\n",
      "    Product9       356643.0           357       999.000000               314                  9.523810                       0.0               0.000000                          -1.0\n",
      "   Product18       351973.0           177      1988.548023               113                 18.079096                       0.0               0.000000                          -1.0\n",
      "   Product19       347884.0           116      2999.000000                93                 16.379310                       0.0               0.000000                          -1.0\n",
      "\n",
      " Team KPIs\n",
      "         team_owner  total_revenue  transactions  avg_order_value  unique_customers  repeat_customers  repeat_customer_rate_pct  median_lead_to_purchase_days  success_txns  coupon_used_txns  payment_success_rate_pct  coupon_usage_rate_pct\n",
      "              Sales     6608411.30          3277      2016.603998              2235               510                 15.563015                          -1.0             0               383                       0.0              11.687519\n",
      "   Customer_Support     3562484.68          3160      1127.368570              2059               598                 18.924051                          -1.0             0               131                       0.0               4.145570\n",
      "          Marketing     1944097.00          1391      1397.625449               916               264                 18.979152                          -1.0             0                58                       0.0               4.169662\n",
      "           Branding     1017189.00          1124       904.972420               814               177                 15.747331                          -1.0             0                53                       0.0               4.715302\n",
      "Product_Development      804196.86           562      1430.955267               395                92                 16.370107                          -1.0             0                37                       0.0               6.583630\n"
     ]
    }
   ],
   "source": [
    "product_group = df.groupby('product_code')\n",
    "\n",
    "product_kpis = product_group.agg(\n",
    "    total_revenue = ('product_amount_with_gst','sum'),\n",
    "    transactions = ('product_amount_with_gst','count'),\n",
    "    avg_order_value = ('product_amount_with_gst','mean'),\n",
    "    unique_customers = ('user_id','nunique')\n",
    ").reset_index()\n",
    "\n",
    "user_txn_counts = df.groupby(['product_code','user_id']).size().reset_index(name='cnt')\n",
    "repeat_customers = user_txn_counts[user_txn_counts['cnt']>1].groupby('product_code').size().reset_index(name='repeat_customers')\n",
    "product_kpis = product_kpis.merge(repeat_customers, on='product_code', how='left')\n",
    "product_kpis['repeat_customers'] = product_kpis['repeat_customers'].fillna(0).astype(int)\n",
    "product_kpis['repeat_customer_rate_pct'] = (product_kpis['repeat_customers'] / product_kpis['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "\n",
    "ps = df.groupby('product_code').agg(\n",
    "    success_txns = ('payment_status', lambda s: (s.str.lower()=='success').sum() ),\n",
    "    coupon_used_txns = ('coupon_code', lambda s: (s != 'NoCoupon').sum() )\n",
    ").reset_index()\n",
    "\n",
    "df['lead_to_purchase_days'] = (df['sales_date'] - df['lead_registered_time']).dt.days\n",
    "lead_median = df.groupby('product_code')['lead_to_purchase_days'].median().reset_index().rename(columns={'lead_to_purchase_days':'median_lead_to_purchase_days'})\n",
    "ps = ps.merge(lead_median, on='product_code', how='left')\n",
    "\n",
    "product_kpis = product_kpis.merge(ps, on='product_code', how='left')\n",
    "product_kpis['payment_success_rate_pct'] = (product_kpis['success_txns'] / product_kpis['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "product_kpis['coupon_usage_rate_pct'] = (product_kpis['coupon_used_txns'] / product_kpis['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "\n",
    "prod_month = df.groupby(['product_code','sales_month'])['product_amount_with_gst'].sum().reset_index()\n",
    "last_months = sorted(prod_month['sales_month'].unique())[-3:]\n",
    "prod_mom = prod_month[prod_month['sales_month'].isin(last_months)].pivot(index='product_code', columns='sales_month', values='product_amount_with_gst').fillna(0)\n",
    "prod_mom.columns = [f\"rev_{c.strftime('%Y-%m')}\" for c in prod_mom.columns]\n",
    "product_kpis = product_kpis.merge(prod_mom.reset_index(), on='product_code', how='left')\n",
    "\n",
    "\n",
    "product_kpis.to_csv(os.path.join(outdir, \"product_kpis.csv\"), index=False)\n",
    "\n",
    "\n",
    "teams = ['Sales','Marketing','Product_Development','Branding','Customer_Support']\n",
    "unique_products = sorted(df['product_code'].unique())\n",
    "product_team_map = {p: teams[i % len(teams)] for i,p in enumerate(unique_products)}\n",
    "df['team_owner'] = df['product_code'].map(product_team_map)\n",
    "\n",
    "team_group = df.groupby('team_owner')\n",
    "team_kpis = team_group.agg(\n",
    "    total_revenue = ('product_amount_with_gst','sum'),\n",
    "    transactions = ('product_amount_with_gst','count'),\n",
    "    avg_order_value = ('product_amount_with_gst','mean'),\n",
    "    unique_customers = ('user_id','nunique')\n",
    ").reset_index()\n",
    "\n",
    "user_counts_team = df.groupby(['team_owner','user_id']).size().reset_index(name='cnt')\n",
    "repeat_team = user_counts_team[user_counts_team['cnt']>1].groupby('team_owner').size().reset_index(name='repeat_customers')\n",
    "team_kpis = team_kpis.merge(repeat_team, on='team_owner', how='left')\n",
    "team_kpis['repeat_customers'] = team_kpis['repeat_customers'].fillna(0).astype(int)\n",
    "team_kpis['repeat_customer_rate_pct'] = (team_kpis['repeat_customers'] / team_kpis['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "\n",
    "lead_team = df.groupby('team_owner')['lead_to_purchase_days'].median().reset_index().rename(columns={'lead_to_purchase_days':'median_lead_to_purchase_days'})\n",
    "team_kpis = team_kpis.merge(lead_team, on='team_owner', how='left')\n",
    "\n",
    "team_ps = df.groupby('team_owner').agg(\n",
    "    success_txns = ('payment_status', lambda s: (s.str.lower()=='success').sum() ),\n",
    "    coupon_used_txns = ('coupon_code', lambda s: (s != 'NoCoupon').sum() )\n",
    ").reset_index()\n",
    "team_kpis = team_kpis.merge(team_ps, on='team_owner', how='left')\n",
    "team_kpis['payment_success_rate_pct'] = (team_kpis['success_txns'] / team_kpis['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "team_kpis['coupon_usage_rate_pct'] = (team_kpis['coupon_used_txns'] / team_kpis['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "\n",
    "team_kpis.to_csv(os.path.join(outdir, \"team_kpis.csv\"), index=False)\n",
    "\n",
    "print(\"Product KPIs (top 10 by revenue)\")\n",
    "display_cols = ['product_code','total_revenue','transactions','avg_order_value','unique_customers','repeat_customer_rate_pct','payment_success_rate_pct','coupon_usage_rate_pct','median_lead_to_purchase_days']\n",
    "print(product_kpis.sort_values('total_revenue', ascending=False)[display_cols].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n Team KPIs\")\n",
    "print(team_kpis.sort_values('total_revenue', ascending=False).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f5656",
   "metadata": {},
   "source": [
    "Q2.If youâ€™re conducting employee-level analysis for each team, what factors and data points? would you check to grade their performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61959e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Employee scoring snapshot \n",
      "employee_id             team  total_revenue  transactions  avg_order_value  avg_response_time_hours  overall_score grade\n",
      "    SAL_E04            Sales     1641512.17           814          2016.60                     32.4       0.816459     A\n",
      "    CUS_E04 Customer_Support     1323852.12          1174          1127.64                     23.0       0.773601     B\n",
      "    CUS_E02 Customer_Support     1378220.28          1223          1126.92                     44.8       0.772574     B\n",
      "    SAL_E03            Sales     1468440.25           728          2017.09                     86.9       0.715627     B\n",
      "    SAL_E01            Sales     1701028.95           844          2015.44                    204.7       0.677616     B\n",
      "    CUS_E01 Customer_Support      783180.61           695          1126.88                     22.5       0.587414     C\n",
      "    SAL_E02            Sales      914719.37           454          2014.80                     72.2       0.564294     C\n",
      "    MAR_E05        Marketing      563291.44           403          1397.75                     11.4       0.547583     C\n",
      "    MAR_E02        Marketing      607259.58           434          1399.22                     72.4       0.506592     C\n",
      "    SAL_E05            Sales      882710.57           438          2015.32                    129.4       0.502913     C\n"
     ]
    }
   ],
   "source": [
    "if 'employee_id' in df.columns:\n",
    "    emp_group = df.groupby('employee_id').agg(\n",
    "        total_revenue = ('product_amount_with_gst','sum'),\n",
    "        transactions = ('product_amount_with_gst','count'),\n",
    "        avg_order_value = ('product_amount_with_gst','mean'),\n",
    "        unique_customers = ('user_id','nunique'),\n",
    "        success_txns = ('payment_status', lambda s: (s.str.lower()=='success').sum())\n",
    "    ).reset_index()\n",
    "    emp_group['payment_success_rate_pct'] = (emp_group['success_txns'] / emp_group['transactions'].replace(0,np.nan) * 100).fillna(0)\n",
    "else:\n",
    "    np.random.seed(2025)\n",
    "    emp_rows = []\n",
    "    for team in team_kpis['team_owner']:\n",
    "        trev = float(team_kpis.loc[team_kpis['team_owner']==team,'total_revenue'].values[0])\n",
    "        ttx = int(team_kpis.loc[team_kpis['team_owner']==team,'transactions'].values[0])\n",
    "        weights = np.random.rand(5)\n",
    "        weights = weights / weights.sum()\n",
    "        for i,w in enumerate(weights, start=1):\n",
    "            emp_id = f\"{team[:3].upper()}_E{i:02d}\"\n",
    "            emp_revenue = round(trev * w,2)\n",
    "            emp_txn = int(round(ttx * w)) if ttx>0 else 0\n",
    "            avg_response_time_hours = round(np.random.uniform(2,72) if team=='Customer_Support' else np.random.uniform(8,240),1)\n",
    "            emp_rows.append({\n",
    "                'employee_id': emp_id,\n",
    "                'team': team,\n",
    "                'total_revenue': emp_revenue,\n",
    "                'transactions': emp_txn,\n",
    "                'avg_order_value': round(emp_revenue / emp_txn,2) if emp_txn>0 else 0,\n",
    "                'avg_response_time_hours': avg_response_time_hours\n",
    "            })\n",
    "    emp_group = pd.DataFrame(emp_rows)\n",
    "\n",
    "\n",
    "emp = emp_group.copy()\n",
    "emp = emp.merge(team_kpis[['team_owner','repeat_customer_rate_pct']], left_on='team', right_on='team_owner', how='left').drop(columns=['team_owner'])\n",
    "def minmax(series):\n",
    "    if series.max()==series.min():\n",
    "        return series.apply(lambda x: 0.5)\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "emp['s_revenue'] = minmax(emp['total_revenue'])\n",
    "emp['s_transactions'] = minmax(emp['transactions'])\n",
    "emp['s_aov'] = minmax(emp['avg_order_value'])\n",
    "emp['s_repeat_rate'] = minmax(emp['repeat_customer_rate_pct'].fillna(0))\n",
    "emp['s_response_time'] = 1 - minmax(emp['avg_response_time_hours'])\n",
    "\n",
    "w_rev, w_txn, w_aov, w_repeat, w_resp = 0.40, 0.15, 0.15, 0.10, 0.20\n",
    "emp['overall_score'] = emp['s_revenue']*w_rev + emp['s_transactions']*w_txn + emp['s_aov']*w_aov + emp['s_repeat_rate']*w_repeat + emp['s_response_time']*w_resp\n",
    "def grade_from_score(s):\n",
    "    if s >= 0.80: return 'A'\n",
    "    if s >= 0.60: return 'B'\n",
    "    if s >= 0.40: return 'C'\n",
    "    return 'D'\n",
    "emp['grade'] = emp['overall_score'].apply(grade_from_score)\n",
    "emp[['employee_id','team','total_revenue','transactions','avg_order_value','avg_response_time_hours','overall_score','grade']].to_csv(os.path.join(outdir,'employee_scores.csv'), index=False)\n",
    "\n",
    "print(\"\\n Employee scoring snapshot \")\n",
    "print(emp.sort_values('overall_score', ascending=False)[['employee_id','team','total_revenue','transactions','avg_order_value','avg_response_time_hours','overall_score','grade']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd735e8",
   "metadata": {},
   "source": [
    "Q3.How would you handle Root Cause Analysis (RCA) as a Data Analyst? Provide a short scenario based on your knowledge and explain the steps involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "909417bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Monthly aggregates \n",
      "sales_month    revenue  total_txns  coupon_used  direct_source_txns  failed_payments  revenue_change_pct\n",
      " 2022-06-01 5788559.64        4432          332                3017             4432            0.000000\n",
      " 2022-07-01 8147819.20        5082          330                4023             5082           40.757282\n",
      "\n",
      " Correlation matrix (monthly signals) \n",
      "                    revenue  total_txns  coupon_used  direct_source_txns  failed_payments\n",
      "revenue                 1.0         1.0         -1.0                 1.0              1.0\n",
      "total_txns              1.0         1.0         -1.0                 1.0              1.0\n",
      "coupon_used            -1.0        -1.0          1.0                -1.0             -1.0\n",
      "direct_source_txns      1.0         1.0         -1.0                 1.0              1.0\n",
      "failed_payments         1.0         1.0         -1.0                 1.0              1.0\n",
      "\n",
      "No month showed >10% revenue decline based on monthly aggregates; RCA rule-based list is empty.\n"
     ]
    }
   ],
   "source": [
    "monthly = df.groupby('sales_month').agg(\n",
    "    revenue=('product_amount_with_gst','sum'),\n",
    "    total_txns=('product_amount_with_gst','count'),\n",
    "    coupon_used = ('coupon_code', lambda s: (s != 'NoCoupon').sum() ),\n",
    "    direct_source_txns = ('source', lambda s: (s=='Direct').sum() ),\n",
    "    failed_payments = ('payment_status', lambda s: (s.str.lower()!='success').sum() )\n",
    ").reset_index().sort_values('sales_month')\n",
    "\n",
    "monthly['revenue_change_pct'] = monthly['revenue'].pct_change().fillna(0) * 100\n",
    "corr_candidates = monthly[['revenue','total_txns','coupon_used','direct_source_txns','failed_payments']]\n",
    "corr_matrix = corr_candidates.corr()\n",
    "\n",
    "rca_rows = []\n",
    "for i in range(1, len(monthly)):\n",
    "    rev_pct = monthly.loc[i,'revenue_change_pct']\n",
    "    if rev_pct < -10:\n",
    "        month = monthly.loc[i,'sales_month'].strftime('%Y-%m')\n",
    "        reasons = []\n",
    "        prev_direct = monthly.loc[i-1,'direct_source_txns']\n",
    "        curr_direct = monthly.loc[i,'direct_source_txns']\n",
    "        if prev_direct>0 and (curr_direct - prev_direct)/prev_direct < -0.10:\n",
    "            reasons.append('Drop in Direct channel transactions (sales/channel)')\n",
    "        if monthly.loc[i,'failed_payments'] > monthly.loc[i-1,'failed_payments']:\n",
    "            reasons.append('Increase in failed/unsuccessful payments (checkout friction)')\n",
    "        if monthly.loc[i,'coupon_used'] < monthly.loc[i-1,'coupon_used']:\n",
    "            reasons.append('Drop in coupon/promo usage (marketing promo reduction)')\n",
    "        if not reasons:\n",
    "            reasons.append('No single dominant signal - suggests deeper analysis needed (pricing, competition, product issues)')\n",
    "        rca_rows.append({\n",
    "            'month': month,\n",
    "            'revenue_change_pct': round(rev_pct,2),\n",
    "            'candidate_reasons': '; '.join(reasons)\n",
    "        })\n",
    "rca_df = pd.DataFrame(rca_rows)\n",
    "\n",
    "monthly.to_csv(os.path.join(outdir,'monthly_aggregates.csv'), index=False)\n",
    "corr_matrix.to_csv(os.path.join(outdir,'monthly_correlation_matrix.csv'), index=False)\n",
    "rca_df.to_csv(os.path.join(outdir,'rca_summary.csv'), index=False)\n",
    "\n",
    "print(\"\\n Monthly aggregates \")\n",
    "print(monthly.to_string(index=False))\n",
    "\n",
    "print(\"\\n Correlation matrix (monthly signals) \")\n",
    "print(corr_matrix.to_string())\n",
    "\n",
    "if rca_df.empty:\n",
    "    print(\"\\nNo month showed >10% revenue decline based on monthly aggregates; RCA rule-based list is empty.\")\n",
    "else:\n",
    "    print(\"\\n RCA flagged months and candidate reasons \")\n",
    "    print(rca_df.to_string(index=False))\n",
    "\n",
    "# plots (matplotlib only)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(monthly['sales_month'].dt.strftime('%Y-%m'), monthly['revenue'], marker='o')\n",
    "plt.title('Monthly Revenue (for RCA view)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir,'rca_monthly_revenue.png'))\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(monthly['sales_month'].dt.strftime('%Y-%m'), monthly['failed_payments'], marker='o')\n",
    "plt.title('Monthly Failed Payments')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Failed Payments Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(outdir,'rca_failed_payments.png'))\n",
    "plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
